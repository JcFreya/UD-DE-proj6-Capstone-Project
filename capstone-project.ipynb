{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "This project attempts to build an ETL pipeline hosted on S3 with the use of Spark so as to set up efficient analytics framework with I94 immigration, global land temperatures and US demographics data. Within the project, we will load data from S3, process the data into analytics tables (fact and dimension tables which will act as the fundamental of further business cases analysis) using Spark based on EDA (exploratory data analysis) result, and load them back into S3. The Spark process will be deployed on a cluster using AWS. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 212.3MB 32kB/s  eta 0:00:010% |                                | 552kB 8.1MB/s eta 0:00:27    0% |▏                               | 1.3MB 8.5MB/s eta 0:00:25    0% |▎                               | 1.7MB 10.1MB/s eta 0:00:21    1% |▎                               | 2.2MB 9.0MB/s eta 0:00:24    1% |▌                               | 3.0MB 9.3MB/s eta 0:00:23    1% |▌                               | 3.4MB 8.8MB/s eta 0:00:24    1% |▋                               | 3.8MB 7.8MB/s eta 0:00:27    1% |▋                               | 4.1MB 8.5MB/s eta 0:00:25    2% |▊                               | 4.5MB 7.8MB/s eta 0:00:27    2% |▉                               | 5.2MB 7.8MB/s eta 0:00:27    2% |▉                               | 5.6MB 8.7MB/s eta 0:00:24    2% |█                               | 6.0MB 9.2MB/s eta 0:00:23    3% |█                               | 6.4MB 8.1MB/s eta 0:00:26    3% |█                               | 6.7MB 5.5MB/s eta 0:00:38    3% |█                               | 7.2MB 8.9MB/s eta 0:00:24    3% |█▏                              | 8.0MB 9.4MB/s eta 0:00:22    4% |█▎                              | 8.8MB 8.8MB/s eta 0:00:24    4% |█▍                              | 9.3MB 9.2MB/s eta 0:00:22    4% |█▌                              | 10.1MB 8.2MB/s eta 0:00:25    4% |█▋                              | 10.5MB 8.5MB/s eta 0:00:24    5% |█▋                              | 10.9MB 8.6MB/s eta 0:00:24    5% |█▊                              | 11.3MB 10.2MB/s eta 0:00:20    5% |█▊                              | 11.7MB 9.0MB/s eta 0:00:23    5% |█▉                              | 12.1MB 8.6MB/s eta 0:00:24    6% |██▏                             | 14.6MB 9.1MB/s eta 0:00:22    7% |██▎                             | 15.4MB 8.2MB/s eta 0:00:24    7% |██▍                             | 15.8MB 8.7MB/s eta 0:00:23    7% |██▍                             | 16.2MB 8.6MB/s eta 0:00:23    8% |██▋                             | 17.0MB 9.8MB/s eta 0:00:20    8% |██▋                             | 17.4MB 8.9MB/s eta 0:00:22    8% |██▊                             | 17.8MB 8.5MB/s eta 0:00:23    9% |███                             | 19.9MB 8.7MB/s eta 0:00:23    9% |███                             | 20.1MB 6.4MB/s eta 0:00:31    9% |███                             | 20.4MB 7.4MB/s eta 0:00:27    9% |███▏                            | 20.8MB 8.2MB/s eta 0:00:24    10% |███▎                            | 21.6MB 7.7MB/s eta 0:00:25    10% |███▍                            | 22.3MB 8.6MB/s eta 0:00:23    10% |███▍                            | 22.7MB 8.0MB/s eta 0:00:24    10% |███▌                            | 23.1MB 7.9MB/s eta 0:00:25    11% |███▋                            | 23.9MB 18.1MB/s eta 0:00:11    11% |███▊                            | 24.8MB 18.1MB/s eta 0:00:11    12% |████                            | 26.6MB 18.4MB/s eta 0:00:11    12% |████▏                           | 27.4MB 17.6MB/s eta 0:00:11    13% |████▎                           | 28.3MB 17.5MB/s eta 0:00:11    13% |████▍                           | 29.3MB 7.9MB/s eta 0:00:24    13% |████▌                           | 29.7MB 6.7MB/s eta 0:00:28    14% |████▌                           | 30.0MB 7.5MB/s eta 0:00:25    14% |████▋                           | 30.8MB 18.1MB/s eta 0:00:11    16% |█████▏                          | 34.2MB 16.9MB/s eta 0:00:11    17% |█████▌                          | 36.2MB 7.0MB/s eta 0:00:25    17% |█████▋                          | 37.2MB 19.1MB/s eta 0:00:10    18% |██████                          | 39.9MB 19.9MB/s eta 0:00:09    19% |██████▏                         | 40.7MB 16.0MB/s eta 0:00:11    19% |██████▏                         | 41.2MB 10.3MB/s eta 0:00:17    19% |██████▎                         | 42.0MB 6.5MB/s eta 0:00:27    19% |██████▍                         | 42.3MB 7.5MB/s eta 0:00:23    20% |██████▍                         | 42.7MB 7.3MB/s eta 0:00:24    20% |██████▌                         | 43.0MB 7.8MB/s eta 0:00:22    20% |██████▌                         | 43.4MB 7.4MB/s eta 0:00:23    20% |██████▊                         | 44.5MB 7.2MB/s eta 0:00:24    21% |██████▉                         | 45.4MB 18.0MB/s eta 0:00:10    21% |███████                         | 46.3MB 18.4MB/s eta 0:00:10    22% |███████                         | 46.8MB 11.7MB/s eta 0:00:15    22% |███████▏                        | 47.2MB 8.3MB/s eta 0:00:20    22% |███████▎                        | 48.2MB 11.1MB/s eta 0:00:15    22% |███████▍                        | 48.7MB 7.5MB/s eta 0:00:22    23% |███████▋                        | 50.2MB 7.2MB/s eta 0:00:23    24% |███████▊                        | 51.2MB 11.3MB/s eta 0:00:15    24% |███████▉                        | 52.2MB 7.7MB/s eta 0:00:21    24% |███████▉                        | 52.3MB 3.3MB/s eta 0:00:49    24% |████████                        | 52.8MB 20.0MB/s eta 0:00:08    26% |████████▍                       | 55.3MB 18.2MB/s eta 0:00:09    26% |████████▌                       | 56.2MB 18.0MB/s eta 0:00:09    27% |████████▉                       | 58.3MB 20.2MB/s eta 0:00:08    27% |█████████                       | 59.3MB 442kB/s eta 0:05:46    28% |█████████                       | 60.1MB 8.6MB/s eta 0:00:18    29% |█████████▌                      | 63.2MB 17.3MB/s eta 0:00:09    30% |█████████▉                      | 65.0MB 18.0MB/s eta 0:00:09    32% |██████████▍                     | 69.0MB 19.6MB/s eta 0:00:08    32% |██████████▌                     | 69.9MB 16.6MB/s eta 0:00:09    33% |██████████▊                     | 71.2MB 4.1MB/s eta 0:00:35    33% |██████████▉                     | 72.0MB 18.5MB/s eta 0:00:08    34% |███████████                     | 72.8MB 19.7MB/s eta 0:00:08    34% |███████████                     | 73.7MB 12.8MB/s eta 0:00:11    35% |███████████▏                    | 74.5MB 16.2MB/s eta 0:00:09    35% |███████████▍                    | 75.4MB 20.3MB/s eta 0:00:07    35% |███████████▌                    | 76.3MB 17.5MB/s eta 0:00:08    36% |███████████▉                    | 78.3MB 18.4MB/s eta 0:00:08    37% |████████████                    | 79.3MB 19.6MB/s eta 0:00:07    38% |████████████▏                   | 81.0MB 15.4MB/s eta 0:00:09    38% |████████████▎                   | 81.5MB 7.3MB/s eta 0:00:19    38% |████████████▍                   | 82.3MB 20.1MB/s eta 0:00:07    39% |████████████▋                   | 83.9MB 16.9MB/s eta 0:00:08    39% |████████████▉                   | 84.8MB 20.9MB/s eta 0:00:07    40% |█████████████                   | 85.9MB 23.1MB/s eta 0:00:06    41% |█████████████▎                  | 88.0MB 18.0MB/s eta 0:00:07    41% |█████████████▍                  | 88.9MB 18.5MB/s eta 0:00:07    42% |█████████████▌                  | 89.8MB 15.5MB/s eta 0:00:08    42% |█████████████▊                  | 91.2MB 12.6MB/s eta 0:00:10    43% |█████████████▉                  | 91.9MB 12.9MB/s eta 0:00:10    43% |██████████████                  | 92.8MB 15.6MB/s eta 0:00:08    44% |██████████████                  | 93.5MB 4.0MB/s eta 0:00:30    44% |██████████████▎                 | 95.0MB 11.3MB/s eta 0:00:11    45% |██████████████▌                 | 96.0MB 19.6MB/s eta 0:00:06    45% |██████████████▋                 | 96.8MB 9.7MB/s eta 0:00:12    45% |██████████████▋                 | 97.0MB 5.9MB/s eta 0:00:20    46% |██████████████▉                 | 98.4MB 13.7MB/s eta 0:00:09    46% |███████████████                 | 99.3MB 19.8MB/s eta 0:00:06    47% |███████████████                 | 100.1MB 14.9MB/s eta 0:00:08    47% |███████████████▎                | 101.0MB 21.5MB/s eta 0:00:06    48% |███████████████▌                | 102.8MB 22.6MB/s eta 0:00:05    49% |███████████████▊                | 104.4MB 16.8MB/s eta 0:00:07    50% |████████████████                | 106.8MB 16.9MB/s eta 0:00:07    50% |████████████████▎               | 107.9MB 22.1MB/s eta 0:00:05    51% |████████████████▌               | 109.5MB 14.8MB/s eta 0:00:07    52% |████████████████▋               | 110.5MB 23.3MB/s eta 0:00:05    52% |█████████████████               | 112.3MB 18.0MB/s eta 0:00:06    53% |█████████████████               | 113.3MB 26.0MB/s eta 0:00:04    53% |█████████████████▎              | 114.4MB 22.5MB/s eta 0:00:05    54% |█████████████████▍              | 115.4MB 16.8MB/s eta 0:00:06    55% |█████████████████▋              | 117.0MB 23.9MB/s eta 0:00:04    56% |██████████████████              | 119.6MB 23.0MB/s eta 0:00:05    56% |██████████████████▏             | 120.8MB 13.3MB/s eta 0:00:07    57% |██████████████████▌             | 122.7MB 21.2MB/s eta 0:00:05    58% |██████████████████▋             | 123.6MB 19.1MB/s eta 0:00:05    58% |██████████████████▊             | 124.6MB 22.4MB/s eta 0:00:04    60% |███████████████████▎            | 127.6MB 24.2MB/s eta 0:00:04    62% |███████████████████▉            | 131.7MB 22.3MB/s eta 0:00:04    62% |████████████████████            | 133.0MB 21.9MB/s eta 0:00:04    63% |████████████████████▏           | 133.9MB 28.5MB/s eta 0:00:03    63% |████████████████████▍           | 135.4MB 14.1MB/s eta 0:00:06    64% |████████████████████▊           | 137.3MB 25.6MB/s eta 0:00:03    65% |█████████████████████           | 139.2MB 28.9MB/s eta 0:00:03    66% |█████████████████████▏          | 140.3MB 24.4MB/s eta 0:00:03    66% |█████████████████████▎          | 141.2MB 18.4MB/s eta 0:00:04    66% |█████████████████████▍          | 142.1MB 17.8MB/s eta 0:00:04    67% |█████████████████████▊          | 144.2MB 19.9MB/s eta 0:00:04    68% |██████████████████████          | 145.4MB 26.2MB/s eta 0:00:03    69% |██████████████████████▏         | 147.3MB 16.7MB/s eta 0:00:04    69% |██████████████████████▎         | 148.0MB 17.7MB/s eta 0:00:04    70% |██████████████████████▍         | 148.7MB 30.0MB/s eta 0:00:03    70% |██████████████████████▋         | 149.7MB 16.8MB/s eta 0:00:04    71% |██████████████████████▊         | 150.8MB 26.6MB/s eta 0:00:03    71% |███████████████████████         | 152.1MB 23.8MB/s eta 0:00:03    72% |███████████████████████         | 153.1MB 19.2MB/s eta 0:00:04    72% |███████████████████████▏        | 154.0MB 18.4MB/s eta 0:00:04    72% |███████████████████████▍        | 154.9MB 17.6MB/s eta 0:00:04    73% |███████████████████████▌        | 156.1MB 25.4MB/s eta 0:00:03    74% |███████████████████████▊        | 157.2MB 19.2MB/s eta 0:00:03    74% |███████████████████████▉        | 158.3MB 25.1MB/s eta 0:00:03    75% |████████████████████████        | 159.5MB 30.6MB/s eta 0:00:02    75% |████████████████████████▎       | 160.8MB 21.6MB/s eta 0:00:03    76% |████████████████████████▍       | 162.0MB 22.0MB/s eta 0:00:03    76% |████████████████████████▋       | 163.3MB 27.1MB/s eta 0:00:02    77% |████████████████████████▉       | 164.5MB 18.9MB/s eta 0:00:03    78% |█████████████████████████       | 165.7MB 37.5MB/s eta 0:00:02    78% |█████████████████████████▏      | 167.0MB 27.7MB/s eta 0:00:02    79% |█████████████████████████▍      | 168.1MB 18.1MB/s eta 0:00:03    79% |█████████████████████████▌      | 169.3MB 20.3MB/s eta 0:00:03    80% |█████████████████████████▊      | 170.4MB 18.3MB/s eta 0:00:03    80% |█████████████████████████▉      | 171.7MB 29.6MB/s eta 0:00:02    81% |██████████████████████████      | 172.9MB 24.3MB/s eta 0:00:02    82% |██████████████████████████▍     | 175.1MB 25.1MB/s eta 0:00:02    83% |██████████████████████████▋     | 176.4MB 20.7MB/s eta 0:00:02    83% |██████████████████████████▉     | 177.7MB 33.1MB/s eta 0:00:02    84% |███████████████████████████     | 178.9MB 26.3MB/s eta 0:00:02    84% |███████████████████████████▏    | 180.3MB 31.7MB/s eta 0:00:02    85% |███████████████████████████▍    | 181.5MB 23.2MB/s eta 0:00:02    86% |███████████████████████████▌    | 182.8MB 29.2MB/s eta 0:00:02    86% |███████████████████████████▊    | 184.0MB 24.3MB/s eta 0:00:02    87% |████████████████████████████    | 185.4MB 30.9MB/s eta 0:00:01    87% |████████████████████████████▏   | 186.6MB 30.0MB/s eta 0:00:01    88% |████████████████████████████▎   | 187.9MB 20.9MB/s eta 0:00:02    88% |████████████████████████████▌   | 188.9MB 19.9MB/s eta 0:00:02    89% |████████████████████████████▋   | 190.0MB 21.0MB/s eta 0:00:02    89% |████████████████████████████▊   | 190.8MB 20.4MB/s eta 0:00:02    90% |█████████████████████████████   | 192.1MB 21.4MB/s eta 0:00:01    90% |█████████████████████████████▏  | 193.2MB 20.4MB/s eta 0:00:01    91% |█████████████████████████████▎  | 194.4MB 25.5MB/s eta 0:00:01    92% |█████████████████████████████▌  | 195.6MB 30.6MB/s eta 0:00:01    92% |█████████████████████████████▋  | 196.7MB 20.7MB/s eta 0:00:01    93% |█████████████████████████████▉  | 197.7MB 21.0MB/s eta 0:00:01    93% |██████████████████████████████  | 198.9MB 26.3MB/s eta 0:00:01    94% |██████████████████████████████▏ | 200.1MB 24.4MB/s eta 0:00:01    94% |██████████████████████████████▍ | 201.3MB 37.6MB/s eta 0:00:01    95% |██████████████████████████████▌ | 202.5MB 20.7MB/s eta 0:00:01    95% |██████████████████████████████▊ | 203.6MB 23.0MB/s eta 0:00:01    96% |██████████████████████████████▉ | 204.9MB 23.3MB/s eta 0:00:01    96% |███████████████████████████████ | 205.8MB 17.5MB/s eta 0:00:01    97% |███████████████████████████████▏| 207.0MB 23.7MB/s eta 0:00:01    97% |███████████████████████████████▍| 208.0MB 23.2MB/s eta 0:00:01    98% |███████████████████████████████▋| 210.1MB 55.1MB/s eta 0:00:01    99% |███████████████████████████████▉| 211.3MB 25.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py4j==0.10.9 (from pyspark)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 14.5MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Running setup.py bdist_wheel for pyspark ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "  Found existing installation: py4j 0.10.7\n",
      "    Uninstalling py4j-0.10.7:\n",
      "      Successfully uninstalled py4j-0.10.7\n",
      "  Found existing installation: pyspark 2.4.3\n",
      "    Can't uninstall 'pyspark'. No files were found to uninstall.\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark --upgrade\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# All imports and installs\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "import os\n",
    "import configparser\n",
    "\n",
    "import utils\n",
    "\n",
    "# Spark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# config information\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.6/site-packages (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "import findspark as fs\n",
    "fs.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "!export PYSPARK_DRIVER_PYTHON=jupyter\n",
    "!export PYSPARK_DRIVER_PYTHON_OPTS='notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8b795d59d20b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create spark session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.jars.packages\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"saurfang:spark-sas7bdat:2.0.0-s_2.11\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menableHiveSupport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                     \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mJVM\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_launch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/java_gateway.py\u001b[0m in \u001b[0;36m_launch_gateway\u001b[0;34m(conf, insecure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "# create spark session\n",
    "spark = SparkSession.builder\\\n",
    ".config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport()\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create spark session\n",
    "spark = utils.creat_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "\n",
    "# I94 SAS Data\n",
    "# fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "# df_immigration = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n",
    "fname = 'immigration_data_sample.csv'\n",
    "df_immigration = pd.read_csv(fname)\n",
    "df_immigration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\t\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport()\\\n",
    ".getOrCreate()\n",
    "\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"sas_data\")\n",
    "df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# us cities demoraphics data\n",
    "fname = 'us-cities-demographics.csv'\n",
    "df_demographics = pd.read_csv(fname)\n",
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demographics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read in temperature data\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temperature = pd.read_csv(fname)\n",
    "df_temperature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temperature.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read in airport codes data\n",
    "fname = 'airport-codes_csv.csv'\n",
    "df_airport_codes = pd.read_csv(fname)\n",
    "df_airport_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport_codes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
